{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code to implement linear regression on a dataset from scratch\n",
    "\n",
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from time import sleep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random dataset\n",
    "x = np.array( [ 2, 3, 4.5, 6, 1.5, 8, 7, 5.4, 4, 6.5, 5, 2.5, 3.5, 4] )\n",
    "y = np.array( [ 2.2, 2.8, 4, 5.7, 1.45, 7.9, 7, 5.8, 4.7, 6, 5, 2.8, 4, 4] )\n",
    "\n",
    "# plotting the dataset\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.show()\n",
    "\n",
    "# printing dataset information and reshaping\n",
    "print(\"Dimensions of x:\", x.shape)\n",
    "print(\"Dimensions of y:\", y.shape)\n",
    "\n",
    "x = x.reshape((x.shape[0], 1))\n",
    "y = y.reshape((y.shape[0], 1))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Dimensions of x after reshaping:\", x.shape)\n",
    "print(\"Dimensions of y after reshaping:\", y.shape)\n",
    "print(\"x: \", x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset by concatenating x and y (Optional)\n",
    "data = np.concatenate( (x,y), axis = 1 )\n",
    "print(data)\n",
    "\n",
    "#finding correlation between x and y \n",
    "np.corrcoef(np.transpose(data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trivia!\n",
    "\n",
    "### What does the correlation coefficient give you an insight about? Can you anticipate the results of regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyper paramater theta (weights)\n",
    "\n",
    "# Randomly initialising theta\n",
    "theta = np.array([[0.9, -1]])\n",
    "# print(theta.shape)\n",
    "\n",
    "# creating bias vector x0\n",
    "x0 = np.ones((x.shape[0], 1))\n",
    "\n",
    "# forming input variable\n",
    "X = np.concatenate((x0, x), axis = 1)\n",
    "# print(X.shape)\n",
    "# print(X)\n",
    "\n",
    "# generating hypothesis, h\n",
    "h = X.dot(theta.T)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(x, y, 'r.', label = 'Training set')\n",
    "plt.plot(x, h, 'b--', label = 'Current hypothesis')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# printing overall loss\n",
    "print(\"\\nLOSS: \", (h - y).T)\n",
    "print(np.sum(abs((h - y)) / len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, y, theta):\n",
    "    h = X.dot(theta.T)\n",
    "    loss = h - y\n",
    "    return h, np.sum(loss ** 2) / (2 * len(X))\n",
    "\n",
    "# For testing the function\n",
    "# print(cost_function(X, y, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(X, y, theta, alpha):\n",
    "    loss = (X.dot(theta.T) - y) \n",
    "    dj = loss.T .dot(X)\n",
    "    \n",
    "    theta_n = theta - alpha * dj\n",
    "    return theta_n\n",
    "\n",
    "# For testing the function\n",
    "# print(\"theta before: \", theta)\n",
    "# theta_n = grad_descent(X, y, theta_n, 0.005)\n",
    "# print(\"theta after: \", theta_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg(epoch, X, y, theta, alpha):\n",
    "    for ep in range(epoch):\n",
    "        \n",
    "        #calculate new theta\n",
    "        theta = grad_descent(X, y, theta, alpha)\n",
    "        \n",
    "        #compute new loss\n",
    "        h, loss = cost_function(X, y, theta)\n",
    "        print(\"Cost function: \", loss)\n",
    "        \n",
    "        #plot\n",
    "        plt.plot(x, y, 'r.', label = 'training data')\n",
    "        plt.plot(x, h, 'b--', label = 'current hypothesis')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        sleep(3)\n",
    "\n",
    "# defining hyper parameters\n",
    "\n",
    "# epochs are the number of times we run our linear regression to minimise the loss\n",
    "# alpha is the learning rate\n",
    "\n",
    "#Both epoch and alpha can be changed and tested on different numbers to minimise loss at a different rate(Advisable)\n",
    "epoch = 15\n",
    "alpha = 0.001\n",
    "linear_reg(epoch, X, y, theta, alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
